# MPL – Stage 2Y (Headless CLI + CI Recipe)

Stage **2Y** adds a **command‑line interface** for running experiments, exporting bundles, validating, and producing analytics — plus a **CI recipe** (GitHub Actions) to automate sweeps and publish artifacts.

> Builds on 2S/2T/2U/2V (bundles, compression, schema, integrity) and core runtime. Node ≥ 18 recommended.

---

## Directory Tree (updated)

```
MPL-Stage-2/
├─ package.json
├─ tsconfig.json
├─ README.md
├─ .github/
│  └─ workflows/
│     └─ mpl-ci.yml               # NEW: CI recipe
├─ Dockerfile                      # NEW: optional containerized CLI
├─ src/
│  ├─ runtime/
│  │  ├─ interpreter.ts
│  │  ├─ monad.ts
│  │  ├─ grid.ts
│  │  └─ topology/
│  │     └─ index.ts
│  ├─ web/
│  │  ├─ rulespec.ts
│  │  ├─ prng.ts
│  │  ├─ schema.ts
│  │  ├─ bundle.ts
│  │  ├─ share2u.ts
│  │  └─ analytics.ts
│  └─ cli/                        # NEW: headless CLI
│     ├─ index.ts                 # entry (commander)
│     ├─ commands/
│     │  ├─ bundle.ts             # export .mplbundle from params or snapshot JSON
│     │  ├─ validate.ts           # validate/migrate/normalize bundles
│     │  ├─ sweep.ts              # run batch sweeps → CSV
│     │  ├─ pareto.ts             # Pareto on CSV → frontier CSV
│     │  └─ share.ts              # make (compressed/chunked) share links → txt
│     └─ util/
│        ├─ io.ts                 # fs helpers (read/write JSON/CSV)
│        ├─ hash.ts               # sha256 hex via node crypto
│        └─ gzip.ts               # gzip/ungzip via zlib
```

Add these scripts to **package.json**:

```json
{
  "type": "module",
  "scripts": {
    "cli": "tsx src/cli/index.ts",
    "build": "tsc -p tsconfig.json",
    "dev:2y": "tsx src/cli/index.ts --help"
  },
  "devDependencies": {
    "tsx": "^4.19.0",
    "typescript": "^5.5.4"
  },
  "dependencies": {
    "commander": "^12.1.0"
  }
}
```

> If your `package.json` already has fields, just merge the **scripts**, **devDependencies**, and **dependencies** lists above.

---

## src/cli/util/hash.ts (NEW)

```ts
import { createHash } from 'node:crypto';
export function sha256Hex(text: string | Uint8Array): string {
  const h = createHash('sha256');
  h.update(typeof text === 'string' ? text : Buffer.from(text));
  return h.digest('hex');
}
```

## src/cli/util/gzip.ts (NEW)

```ts
import { gzipSync, gunzipSync } from 'node:zlib';
export const gzip = (s: string | Uint8Array) => gzipSync(typeof s==='string'? Buffer.from(s) : Buffer.from(s));
export const gunzip = (b: Uint8Array) => gunzipSync(Buffer.from(b));
```

## src/cli/util/io.ts (NEW)

```ts
import { promises as fs } from 'node:fs';
import path from 'node:path';

export async function ensureDir(p: string){ await fs.mkdir(path.dirname(p), { recursive: true }); }
export async function readJSON<T=any>(p: string): Promise<T>{ const txt = await fs.readFile(p, 'utf8'); return JSON.parse(txt); }
export async function writeJSON(p: string, obj: any){ await ensureDir(p); await fs.writeFile(p, JSON.stringify(obj, null, 2), 'utf8'); }
export async function writeText(p: string, s: string){ await ensureDir(p); await fs.writeFile(p, s, 'utf8'); }
```

---

## src/cli/commands/bundle.ts (NEW)

```ts
import { Command } from 'commander';
import type { Manifest } from '../../web/bundle.js';
import { writeJSON, readJSON } from '../util/io.js';
import { sha256Hex } from '../util/hash.js';

function parseSize(s: string){ const m=s.match(/^(\d+)x(\d+)$/i); if(!m) throw new Error('size must be WxH'); return { width:Number(m[1]), height:Number(m[2]) }; }

export function bundleCmd(){
  const cmd = new Command('bundle')
    .description('Create a .mplbundle from params or a snapshot JSON')
    .option('--from-snapshot <file>', 'snapshot JSON (width,height,cells)')
    .option('--rule <B/S>', 'rule, e.g. B3/S23', 'B3/S23')
    .option('--seed <n>', 'PRNG seed', (v)=>Number(v), 1)
    .option('--steps <n>', 'intended steps for reproduce', (v)=>Number(v), 200)
    .option('--size <WxH>', 'grid size, e.g. 40x30', '40x30')
    .option('--topology <name>', 'Moore|VonNeumann', 'Moore')
    .option('--edges <name>', 'Clip|Wrap', 'Clip')
    .option('--random-p <float>', 'p(alive) if init=random', (v)=>Number(v), 0.22)
    .requiredOption('--out <file>', 'output path (.mplbundle)')
    .action(async (opts)=>{
      let man: Manifest;
      if (opts.fromSnapshot){
        const snap = await readJSON<any>(opts.fromSnapshot);
        if (!snap.cells) throw new Error('snapshot missing cells[]');
        man = {
          schema: 'mpl-bundle@1', created: new Date().toISOString(), engine: { version: '2Y' },
          env: { ...parseSize(opts.size), topology: opts.topology, edges: opts.edges },
          rule: String(opts.rule).toUpperCase(), seed: Number(opts.seed), steps: Number(opts.steps),
          init: 'snapshot', cells: snap.cells
        };
      } else {
        man = {
          schema: 'mpl-bundle@1', created: new Date().toISOString(), engine: { version: '2Y' },
          env: { ...parseSize(opts.size), topology: opts.topology, edges: opts.edges },
          rule: String(opts.rule).toUpperCase(), seed: Number(opts.seed), steps: Number(opts.steps),
          init: 'random', p: Number(opts.randomP)
        } as Manifest;
      }
      await writeJSON(opts.out, man);
      console.log('Wrote', opts.out, 'sha256=', sha256Hex(JSON.stringify(man)));
    });
  return cmd;
}
```

## src/cli/commands/validate.ts (NEW)

```ts
import { Command } from 'commander';
import { readJSON, writeJSON } from '../util/io.js';
import { validateManifest, normalize, looksLikeSnapshot, migrateSnapshot } from '../../web/schema.js';

export function validateCmd(){
  const cmd = new Command('validate')
    .description('Validate/migrate/normalize a bundle or snapshot JSON')
    .requiredOption('--in <file>', 'input .mplbundle or snapshot.json')
    .option('--out <file>', 'write normalized bundle here')
    .action(async (opts)=>{
      const raw = await readJSON<any>(opts.in);
      let v = validateManifest(raw);
      if (!v.ok && looksLikeSnapshot(raw)) v = validateManifest(migrateSnapshot(raw));
      console.log('OK:', v.ok); if (v.errors?.length) console.log('Errors:', v.errors); if (v.warnings?.length) console.log('Warnings:', v.warnings);
      if (!v.ok) process.exitCode = 1; else if (opts.out){ await writeJSON(opts.out, normalize(v.manifest!)); console.log('Wrote normalized →', opts.out); }
    });
  return cmd;
}
```

## src/cli/commands/sweep.ts (NEW)

```ts
import { Command } from 'commander';
import { Grid2D } from '../../runtime/grid.js';
import { Interpreter } from '../../runtime/interpreter.js';
import { Moore } from '../../runtime/topology/index.js';
import { Monad } from '../../runtime/monad.js';
import { createRng } from '../../web/prng.js';
import { rulesFromSpec, parseBS } from '../../web/rulespec.js';
import { writeText } from '../util/io.js';

function parseSize(s: string){ const m=s.match(/^(\d+)x(\d+)$/i); if(!m) throw new Error('size must be WxH'); return { W:Number(m[1]), H:Number(m[2]) }; }
function parseSeeds(s: string){
  if (s.includes('..')){ const [a,b] = s.split('..').map(Number); return Array.from({length: b-a+1}, (_,i)=> a+i); }
  return s.split(',').map(n=> Number(n.trim())).filter(n=> Number.isFinite(n));
}

export function sweepCmd(){
  const cmd = new Command('sweep')
    .description('Run headless sweeps over rules × seeds and emit CSV of aggregates')
    .requiredOption('--rules <list>', 'comma‑sep rules, e.g. B3/S23,B36/S23')
    .requiredOption('--seeds <spec>', 'comma list or range A..B, e.g. 1..10')
    .option('--size <WxH>', 'grid size', '40x30')
    .option('--steps <n>', 'steps per run', (v)=>Number(v), 200)
    .option('--p <float>', 'initial alive probability', (v)=>Number(v), 0.22)
    .requiredOption('--out <file>', 'output CSV path')
    .action(async (opts)=>{
      const { W,H } = parseSize(opts.size); const steps=Number(opts.steps); const p=Number(opts.p);
      const rules = String(opts.rules).split(',').map(s=> s.trim()); const seeds = parseSeeds(String(opts.seeds));
      const rows: string[] = ['id,rule,seed,steps,alive_final,density_mean,density_std,alive_peak,survival_ratio'];
      for (const rule of rules){
        for (const seed of seeds){
          const intr = new Interpreter(rulesFromSpec(parseBS(rule)));
          const grid = new Grid2D(W, H, intr, new Moore());
          const rng = createRng(seed);
          for (let y=0;y<H;y++) for (let x=0;x<W;x++) (grid as any).cells[y][x] = rng.random()<p? new Monad({alive:true}) : null;
          let alive_peak=0; const densities:number[]=[];
          for (let t=0;t<steps;t++){
            let alive=0; for (let y=0;y<H;y++) for (let x=0;x<W;x++){ const m=(grid as any).cells[y][x]; if(m?.state?.alive) alive++; }
            alive_peak = Math.max(alive_peak, alive);
            densities.push(alive/(W*H));
            grid.tick();
          }
          const alive_final = densities.at(-1)!*(W*H);
          const mu = densities.reduce((a,b)=>a+b,0)/densities.length;
          const sigma = Math.sqrt(densities.reduce((s,v)=> s+(v-mu)*(v-mu),0)/densities.length);
          const row = {
            id: `${rule}@${seed}`,
            rule, seed, steps,
            alive_final: Math.round(alive_final),
            density_mean: mu,
            density_std: sigma,
            alive_peak,
            survival_ratio: densities.at(-1)!
          };
          rows.push([row.id,row.rule,row.seed,row.steps,row.alive_final,row.density_mean,row.density_std,row.alive_peak,row.survival_ratio].join(','));
          console.log('done', row.id);
        }
      }
      await writeText(opts.out, rows.join('\n'));
      console.log('Wrote', opts.out);
    });
  return cmd;
}
```

## src/cli/commands/pareto.ts (NEW)

```ts
import { Command } from 'commander';
import { promises as fs } from 'node:fs';

type Row = Record<string,string>;

function parseCSV(text: string): Row[]{
  const [hdr, ...lines] = text.trim().split(/\r?\n/); const keys = hdr.split(',');
  return lines.map(l => { const vals=l.split(','); const o:Row={}; keys.forEach((k,i)=> o[k]=vals[i]); return o; });
}

function dominates(a:Row, b:Row, objs:{key:string,dir:'max'|'min'}[]){
  let better=0, worse=0; for (const o of objs){ const av=Number(a[o.key]); const bv=Number(b[o.key]); const cmp = o.dir==='max'? (av-bv):(bv-av); if (cmp>0) better++; else if (cmp<0) worse++; }
  return better>0 && worse===0;
}

export function paretoCmd(){
  const cmd = new Command('pareto')
    .description('Compute Pareto frontier from a sweep CSV (2 objectives)')
    .requiredOption('--csv <file>', 'input CSV (from sweep)')
    .requiredOption('--obj <key:dir...>', 'objective spec, repeatable (e.g. alive_final:max)', (v,acc)=>{ acc.push(v); return acc; }, [] as string[])
    .requiredOption('--out <file>', 'output CSV of frontier')
    .action(async (opts)=>{
      const text = await fs.readFile(opts.csv, 'utf8'); const rows = parseCSV(text);
      const objs = (opts.obj as string[]).map(s=>{ const [k,d]=s.split(':'); return { key:k, dir:(d==='min'?'min':'max') as 'max'|'min' }; });
      const keep: Row[] = [];
      for (const r of rows){ let dom=false; for (const q of rows){ if (r===q) continue; if (dominates(q,r,objs)){ dom=true; break; } } if (!dom) keep.push(r); }
      const header = Object.keys(rows[0]||{});
      const out = [header.join(','), ...keep.map(r => header.map(k=> r[k]??'').join(','))].join('\n');
      await fs.writeFile(opts.out, out, 'utf8'); console.log('Frontier size', keep.length, '→', opts.out);
    });
  return cmd;
}
```

## src/cli/commands/share.ts (NEW)

```ts
import { Command } from 'commander';
import { promises as fs } from 'node:fs';
import { gzip } from '../util/gzip.js';
import { sha256Hex } from '../util/hash.js';

function b64url(buf: Uint8Array){ return Buffer.from(buf).toString('base64').replace(/\+/g,'-').replace(/\//g,'_').replace(/=+$/,''); }
function chunk(s: string, n: number){ const out: string[]=[]; for (let i=0;i<s.length;i+=n) out.push(s.slice(i,i+n)); return out; }

export function shareCmd(){
  const cmd = new Command('share')
    .description('Create compressed (and if needed chunked) share links for a bundle')
    .requiredOption('--in <file>', '.mplbundle input')
    .option('--base <url>', 'base viewer URL', 'https://example.com/index-2u.html')
    .option('--max <n>', 'max chars per link (data payload)', (v)=>Number(v), 1800)
    .requiredOption('--out <file>', 'write links text file')
    .action(async (opts)=>{
      const json = await fs.readFile(opts.in, 'utf8');
      const sha = sha256Hex(json); const gz = gzip(json);
      const enc = b64url(gz);
      const need = enc.length > opts.max ? chunk(enc, opts.max) : [enc];
      let text='';
      if (need.length===1){ text = `${opts.base}#bundle=${need[0]}&algo=gzip&sha256=${sha}`; }
      else { need.forEach((part,i)=>{ text += `${opts.base}#id=${sha.slice(0,12)}&parts=${need.length}&i=${i}&data=${part}&algo=gzip&sha256=${sha}\n`; }); }
      await fs.writeFile(opts.out, text.trim()+"\n", 'utf8');
      console.log(`Wrote ${opts.out} (${need.length} link${need.length>1?'s':''}), sha256=${sha}`);
    });
  return cmd;
}
```

## src/cli/index.ts (NEW)

```ts
#!/usr/bin/env node
import { Command } from 'commander';
import { bundleCmd } from './commands/bundle.js';
import { validateCmd } from './commands/validate.js';
import { sweepCmd } from './commands/sweep.js';
import { paretoCmd } from './commands/pareto.js';
import { shareCmd } from './commands/share.js';

const program = new Command();
program
  .name('mpl')
  .description('MPL headless CLI (Stage 2Y)')
  .version('2Y.0.0');

program.addCommand(bundleCmd());
program.addCommand(validateCmd());
program.addCommand(sweepCmd());
program.addCommand(paretoCmd());
program.addCommand(shareCmd());

program.parseAsync(process.argv);
```

---

## GitHub Actions CI — .github/workflows/mpl-ci.yml (NEW)

```yaml
name: mpl-ci
on:
  workflow_dispatch:
  push:
    branches: [ main, master ]
  pull_request:

jobs:
  sweeps:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
      - run: npm ci
      - run: npm run cli -- --help
      - name: Run sweep
        run: |
          mkdir -p out
          npm run cli -- sweep --rules "B3/S23,B36/S23" --seeds 1..5 --size 40x30 --steps 200 --p 0.22 --out out/sweep.csv
      - name: Pareto frontier
        run: |
          npm run cli -- pareto --csv out/sweep.csv --obj alive_final:max --obj density_std:min --out out/frontier.csv
      - name: Bundle example
        run: |
          npm run cli -- bundle --rule B3/S23 --seed 123 --steps 200 --size 40x30 --out out/exp.mplbundle
      - name: Share links
        run: |
          npm run cli -- share --in out/exp.mplbundle --base https://example.com/index-2u.html --max 1800 --out out/links.txt
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mpl-artifacts
          path: out/**
```

---

## Dockerfile (NEW – optional)

```dockerfile
# Build a minimal container that can run the CLI.
FROM node:20-alpine
WORKDIR /app
COPY package.json package-lock.json* ./
RUN npm ci --omit=dev && npm i -D tsx typescript
COPY . .
ENTRYPOINT ["npm","run","cli","--"]
```

---

## README addendum (2Y)

````md
### 2Y – Headless CLI + CI

Install:
```bash
npm i
````

Run CLI (help):

```bash
npm run cli -- --help
```

Common tasks:

```bash
# 1) Make a bundle (random init)
npm run cli -- bundle --rule B3/S23 --seed 123 --steps 200 --size 40x30 --out out/exp.mplbundle

# 2) Validate / normalize
npm run cli -- validate --in out/exp.mplbundle --out out/exp.normalized.mplbundle

# 3) Headless sweep → CSV
npm run cli -- sweep --rules "B3/S23,B36/S23" --seeds 1..8 --size 40x30 --steps 200 --p 0.22 --out out/sweep.csv

# 4) Pareto frontier from CSV
npm run cli -- pareto --csv out/sweep.csv --obj alive_final:max --obj density_std:min --out out/frontier.csv

# 5) Make compressed share link(s)
npm run cli -- share --in out/exp.mplbundle --base https://your-host/index-2u.html --max 1800 --out out/links.txt
```

CI:

* Enable GitHub Actions and commit `.github/workflows/mpl-ci.yml`.
* Artifacts (`out/…`) will be available for download on each run.

**Notes**

* The CLI reuses the same runtime and schema logic as the browser stages.
* Node ≥ 18 is required (for `fetch`, ESM, modern TS). For older Node, use the provided Dockerfile.

```
```
